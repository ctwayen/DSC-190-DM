{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.stem import PorterStemmer\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LinearRegression \n",
    "from dateutil.rrule import rrule, DAILY \n",
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn.metrics import r2_score \n",
    "import math \n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.preprocessing import FunctionTransformer \n",
    "from sklearn.compose import ColumnTransformer \n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn import linear_model\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import re\n",
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\xinrui\n",
      "[nltk_data]     zhan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\xinrui\n",
      "[nltk_data]     zhan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(data):\n",
    "    stop_words = set(stopwords.words('english')) \n",
    "    word_tokens = word_tokenize(data) \n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words] \n",
    "    return ' '.join(filtered_sentence)\n",
    "\n",
    "def remove_punctuation(data):\n",
    "    symbols = \"!\\\"#$%&()*+-./:;<=>?@[\\]^_`{|}~\\n\"\n",
    "    for i in symbols:\n",
    "        data = str.replace(data, i, ' ')\n",
    "    return data\n",
    "\n",
    "def remove_apostrophe(data):\n",
    "    return str.replace(data, \"'\", \"\")\n",
    "\n",
    "def remove_single_characters(data):\n",
    "    new_text = \"\"\n",
    "    words = word_tokenize(data)\n",
    "    for w in words:\n",
    "        if len(w) > 1:\n",
    "            new_text = new_text + \" \" + w\n",
    "    return new_text\n",
    "\n",
    "def stemming(data):\n",
    "    return PorterStemmer().stem(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    data = str(data)\n",
    "    data = data.lower()\n",
    "    data = remove_punctuation(data)\n",
    "    data = remove_apostrophe(data)\n",
    "    data = remove_single_characters(data)\n",
    "    data = remove_stop_words(data)\n",
    "    data = stemming(data)\n",
    "    data = remove_punctuation(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xinrui zhan\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3049: DtypeWarning: Columns (30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_label(x):\n",
    "    if x > 700:\n",
    "        return \"high\"\n",
    "    elif x>500:\n",
    "        return 'less high'\n",
    "    elif x>100:\n",
    "        return \"middle\"\n",
    "    else:\n",
    "        return 'low'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'name', 'summary', 'space', 'description', 'experiences_offered',\n",
       "       'neighborhood_overview', 'notes', 'transit', 'access', 'interaction',\n",
       "       'house_rules', 'host_id', 'host_name', 'host_since', 'host_location',\n",
       "       'host_about', 'host_response_time', 'host_response_rate',\n",
       "       'host_acceptance_rate', 'host_is_superhost', 'host_neighbourhood',\n",
       "       'host_listings_count', 'host_verifications', 'host_has_profile_pic',\n",
       "       'host_identity_verified', 'neighbourhood_cleansed',\n",
       "       'neighbourhood_group_cleansed', 'city', 'state', 'zipcode', 'market',\n",
       "       'country_code', 'country', 'property_type', 'room_type', 'accommodates',\n",
       "       'bathrooms', 'bedrooms', 'beds', 'bed_type', 'amenities', 'square_feet',\n",
       "       'price', 'guests_included', 'extra_people', 'minimum_nights',\n",
       "       'maximum_nights', 'number_of_reviews', 'first_review', 'last_review',\n",
       "       'review_scores_rating', 'review_scores_accuracy',\n",
       "       'review_scores_cleanliness', 'review_scores_checkin',\n",
       "       'review_scores_communication', 'review_scores_location',\n",
       "       'review_scores_value', 'instant_bookable', 'is_business_travel_ready',\n",
       "       'cancellation_policy', 'require_guest_profile_picture',\n",
       "       'require_guest_phone_verification', 'calculated_host_listings_count',\n",
       "       'reviews_per_month'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                            Subway: 2,3,4,5,A,C,B,Q,G\n",
       "1    PUBLIC TRANSPORTATION: Conveniently near all p...\n",
       "2                                                  NaN\n",
       "3                                                  NaN\n",
       "4    Super convenient to almost all subway lines. A...\n",
       "Name: transit, dtype: object"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.transit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22896416005724848"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(train_df.review_scores_cleanliness.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000.0    27\n",
       "500.0     27\n",
       "0.0       22\n",
       "700.0     20\n",
       "800.0     15\n",
       "400.0     14\n",
       "1200.0    13\n",
       "900.0     13\n",
       "750.0     13\n",
       "600.0     12\n",
       "450.0     11\n",
       "850.0     10\n",
       "1500.0     8\n",
       "650.0      8\n",
       "550.0      7\n",
       "950.0      7\n",
       "2000.0     6\n",
       "1800.0     6\n",
       "350.0      5\n",
       "250.0      5\n",
       "1100.0     4\n",
       "200.0      4\n",
       "1600.0     4\n",
       "300.0      4\n",
       "1300.0     3\n",
       "100.0      3\n",
       "150.0      3\n",
       "140.0      3\n",
       "1400.0     2\n",
       "3600.0     2\n",
       "          ..\n",
       "484.0      1\n",
       "96.0       1\n",
       "210.0      1\n",
       "790.0      1\n",
       "915.0      1\n",
       "330.0      1\n",
       "720.0      1\n",
       "240.0      1\n",
       "245.0      1\n",
       "17.0       1\n",
       "2160.0     1\n",
       "175.0      1\n",
       "5000.0     1\n",
       "1090.0     1\n",
       "982.0      1\n",
       "875.0      1\n",
       "12.0       1\n",
       "1150.0     1\n",
       "1010.0     1\n",
       "220.0      1\n",
       "925.0      1\n",
       "135.0      1\n",
       "410.0      1\n",
       "2200.0     1\n",
       "269.0      1\n",
       "665.0      1\n",
       "1750.0     1\n",
       "725.0      1\n",
       "625.0      1\n",
       "540.0      1\n",
       "Name: square_feet, Length: 83, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.square_feet.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review_scores_cleanliness\n",
       "2.0     126.340206\n",
       "3.0      85.000000\n",
       "4.0     119.275229\n",
       "5.0     120.943662\n",
       "6.0     127.127563\n",
       "7.0     124.332298\n",
       "8.0     121.365693\n",
       "9.0     135.563164\n",
       "10.0    145.688609\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.groupby('review_scores_cleanliness')['price'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      18007\n",
       "25      2799\n",
       "20      2528\n",
       "10      2018\n",
       "50      1800\n",
       "15      1538\n",
       "30      1240\n",
       "40       569\n",
       "35       510\n",
       "100      333\n",
       "5        324\n",
       "75       253\n",
       "45       181\n",
       "60       126\n",
       "12        82\n",
       "7         78\n",
       "80        63\n",
       "55        60\n",
       "18        58\n",
       "29        57\n",
       "19        52\n",
       "39        51\n",
       "300       46\n",
       "150       45\n",
       "8         41\n",
       "70        35\n",
       "49        32\n",
       "9         32\n",
       "200       32\n",
       "65        31\n",
       "       ...  \n",
       "57         2\n",
       "130        2\n",
       "105        2\n",
       "129        2\n",
       "110        2\n",
       "31         2\n",
       "52         2\n",
       "115        2\n",
       "145        2\n",
       "67         1\n",
       "285        1\n",
       "225        1\n",
       "189        1\n",
       "190        1\n",
       "68         1\n",
       "51         1\n",
       "61         1\n",
       "199        1\n",
       "89         1\n",
       "83         1\n",
       "88         1\n",
       "56         1\n",
       "119        1\n",
       "76         1\n",
       "87         1\n",
       "149        1\n",
       "143        1\n",
       "175        1\n",
       "176        1\n",
       "41         1\n",
       "Name: extra_people, Length: 98, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.extra_people.apply(lambda x: int(x[:-3].replace('$', ''))).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.amenities = train_df.amenities.apply(preprocess).apply(lambda x: word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = {}\n",
    "for lst in train_df.amenities:\n",
    "    for item in lst:\n",
    "        if item not in temp.keys():\n",
    "            temp[item] = 1\n",
    "        else:\n",
    "            temp[item]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "values = np.array(list(temp.values()))\n",
    "keys = np.array(list(temp.keys()))\n",
    "ind = (values > 1000) & (values < 33000)\n",
    "display(len(keys[ind]))\n",
    "related = keys[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(lst):\n",
    "    temp = np.zeros(131)\n",
    "    for i in range(len(related)):\n",
    "        if related[i] in lst:\n",
    "            temp[i] = 1\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33538, 65)"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wifi',\n",
       " 'air',\n",
       " 'conditioning',\n",
       " 'kitchen',\n",
       " 'gym',\n",
       " 'breakfast',\n",
       " 'elevator',\n",
       " 'heating',\n",
       " 'washer',\n",
       " 'dryer',\n",
       " 'smoke',\n",
       " 'detector',\n",
       " 'carbon',\n",
       " 'monoxide',\n",
       " 'detector',\n",
       " 'first',\n",
       " 'aid',\n",
       " 'kit',\n",
       " 'safety',\n",
       " 'card',\n",
       " 'fire',\n",
       " 'extinguisher',\n",
       " 'essentials',\n",
       " 'shampoo',\n",
       " 'hangers',\n",
       " 'hair',\n",
       " 'dryer',\n",
       " 'iron',\n",
       " 'laptop',\n",
       " 'friendly',\n",
       " 'workspace',\n",
       " 'self',\n",
       " 'check',\n",
       " 'building',\n",
       " 'staff',\n",
       " 'hot',\n",
       " 'water',\n",
       " 'luggage',\n",
       " 'dropoff',\n",
       " 'allow']"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(preprocess(train_df.amenities[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df = pd.DataFrame()\n",
    "summary_df['transit'] = train_df.transit.apply(preprocess) \n",
    "summary_df['label'] = train_df.price.apply(lambda x: p_label(x))\n",
    "words_in_bin = summary_df.groupby('label')['transit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_dct = {}\n",
    "for label, grp in words_in_bin:\n",
    "    grp = grp.to_list()\n",
    "    #display(type(grp[0]))\n",
    "    para = ' '.join(grp)\n",
    "    words_dct[label] = para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_dct.keys()\n",
    "words = list(words_dct.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = {}\n",
    "for i in range(len(words)):\n",
    "    sentence = words[i]\n",
    "    tokens = word_tokenize(sentence)\n",
    "    for w in tokens:\n",
    "        try:\n",
    "            df[w].add(i)\n",
    "        except:\n",
    "            df[w] = {i}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.keys():\n",
    "    df[i] = len(df[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10825"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = {}\n",
    "for i in words_dct.keys():\n",
    "    para = words_dct[i]\n",
    "    tokens = word_tokenize(para)\n",
    "    temp = {}\n",
    "    for token in tokens:\n",
    "        try:\n",
    "            temp[token] += 1\n",
    "        except:\n",
    "            temp[token] = 1\n",
    "    tf[i] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_tens = []\n",
    "for i in words_dct.keys():\n",
    "    tf_idf = []\n",
    "    for word in tf[i].keys():\n",
    "        tf_ = tf[i][word]\n",
    "        df_ = df[word]\n",
    "        idf_ = (5)/(df_+1)\n",
    "        tf_idf_ = math.log(idf_)*tf_\n",
    "        tf_idf.append(tf_idf_)\n",
    "    temp = pd.DataFrame()\n",
    "    temp['word'] = tf[i].keys()\n",
    "    temp['tf_idf'] = tf_idf\n",
    "    top_ten = list(temp.sort_values('tf_idf', ascending=False)['word'][:20])\n",
    "    top_tens.append(top_ten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wyndham</td>\n",
       "      <td>bentley</td>\n",
       "      <td>•subway</td>\n",
       "      <td>rockette</td>\n",
       "      <td>highline</td>\n",
       "      <td>sampling</td>\n",
       "      <td>headquarters</td>\n",
       "      <td>kicks</td>\n",
       "      <td>going</td>\n",
       "      <td>concierge</td>\n",
       "      <td>bathing</td>\n",
       "      <td>m55</td>\n",
       "      <td>•34</td>\n",
       "      <td>regis</td>\n",
       "      <td>suit</td>\n",
       "      <td>•nyc</td>\n",
       "      <td>provid</td>\n",
       "      <td>166</td>\n",
       "      <td>figur</td>\n",
       "      <td>meadowland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wyndham</td>\n",
       "      <td>•34</td>\n",
       "      <td>•nyc</td>\n",
       "      <td>¬–</td>\n",
       "      <td>35</td>\n",
       "      <td>50</td>\n",
       "      <td>quick</td>\n",
       "      <td>rockette</td>\n",
       "      <td>sampling</td>\n",
       "      <td>kicks</td>\n",
       "      <td>depending</td>\n",
       "      <td>circle</td>\n",
       "      <td>headquarters</td>\n",
       "      <td>fq</td>\n",
       "      <td>em6</td>\n",
       "      <td>m55</td>\n",
       "      <td>tribecca</td>\n",
       "      <td>lispendard</td>\n",
       "      <td>hellgate</td>\n",
       "      <td>volvo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>utica</td>\n",
       "      <td>along</td>\n",
       "      <td>road</td>\n",
       "      <td>transfer</td>\n",
       "      <td>myrtle</td>\n",
       "      <td>parkway</td>\n",
       "      <td>quick</td>\n",
       "      <td>av</td>\n",
       "      <td>35</td>\n",
       "      <td>morgan</td>\n",
       "      <td>halsey</td>\n",
       "      <td>nostrand</td>\n",
       "      <td>mall</td>\n",
       "      <td>graham</td>\n",
       "      <td>blvd</td>\n",
       "      <td>coming</td>\n",
       "      <td>rail</td>\n",
       "      <td>mta</td>\n",
       "      <td>wyckoff</td>\n",
       "      <td>b38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>along</td>\n",
       "      <td>m15</td>\n",
       "      <td>av</td>\n",
       "      <td>south</td>\n",
       "      <td>quick</td>\n",
       "      <td>parkway</td>\n",
       "      <td>extremely</td>\n",
       "      <td>road</td>\n",
       "      <td>share</td>\n",
       "      <td>transfer</td>\n",
       "      <td>coming</td>\n",
       "      <td>35</td>\n",
       "      <td>1st</td>\n",
       "      <td>nassau</td>\n",
       "      <td>utica</td>\n",
       "      <td>graham</td>\n",
       "      <td>locations</td>\n",
       "      <td>apart</td>\n",
       "      <td>nostrand</td>\n",
       "      <td>making</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0        1        2         3         4         5             6   \\\n",
       "0  wyndham  bentley  •subway  rockette  highline  sampling  headquarters   \n",
       "1  wyndham      •34     •nyc        ¬–        35        50         quick   \n",
       "2    utica    along     road  transfer    myrtle   parkway         quick   \n",
       "3    along      m15       av     south     quick   parkway     extremely   \n",
       "\n",
       "         7         8          9          10        11            12      13  \\\n",
       "0     kicks     going  concierge    bathing       m55           •34   regis   \n",
       "1  rockette  sampling      kicks  depending    circle  headquarters      fq   \n",
       "2        av        35     morgan     halsey  nostrand          mall  graham   \n",
       "3      road     share   transfer     coming        35           1st  nassau   \n",
       "\n",
       "      14      15         16          17        18          19  \n",
       "0   suit    •nyc     provid         166     figur  meadowland  \n",
       "1    em6     m55   tribecca  lispendard  hellgate       volvo  \n",
       "2   blvd  coming       rail         mta   wyckoff         b38  \n",
       "3  utica  graham  locations       apart  nostrand      making  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_tens = pd.DataFrame(top_tens)\n",
    "top_tens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sum(summary):\n",
    "    words = word_tokenize(summary)\n",
    "    if 'bentley' in words:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "after_pre =train_df.transit.apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transit\n",
       "0    33537\n",
       "1        1\n",
       "Name: price, dtype: int64"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.loc[:, 'transit'] = after_pre.apply(extract_sum)\n",
    "train_df.groupby('transit')['price'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transit\n",
       "0     145.151206\n",
       "1    1020.000000\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.groupby('transit')['price'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test.csv')\n",
    "t_after_pre =test_df.summary.apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "description\n",
       "0    17209\n",
       "1      128\n",
       "Name: beds, dtype: int64"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.loc[:, 'transit'] = t_after_pre.apply(extract_sum)\n",
    "test_df.groupby('transit')['beds'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
